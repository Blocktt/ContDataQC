, "\n\n")
cat(msg)
msg <- paste0("**Spike test threshold:** "
, 1.5
, "\n\n")
cat(msg)
msg <- paste0("**Measured value difference:** "
, diff_spike
, "\n\n")
cat(msg)
msg <- "Some statement about spike test, Pass or Fail\n\n"
cat(msg)
# Get parameter
lab.title <- paste0("Deployment end/start comparison; ", i_A_end)
lab.subtitle <- paste0(i, " (A) and ", i+1, " (B)")
# Plot, box
p_box <- ggplot2::ggplot(df_plot, ggplot2::aes_string(x = col_Comp
, y = fun.col.Param
, fill = col_Comp)) +
ggplot2::geom_boxplot() +
ggplot2::labs(title = lab.title
, subtitle = lab.subtitle
, x = "Deployments") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none")
print(p_box)
cat("\n\n")
# Plot, time series
#x_vline <- length(vec_A) + .5 # (i_A_end + i_B_start)/2
x_vline <- i_A_end + i_diff/2 * 3600
# scale_x_date(labels = date_format("%m-%Y"))
# ensure data is date
#df_plot[, "Date.Time"] <- as.Date.POSIXct(df_plot[, "Date.Time"])
p_scat <- ggplot2::ggplot(df_plot, ggplot2::aes_string(x = fun.col.DateTime
, y = fun.col.Param
, color = col_Comp)) +
ggplot2::geom_point() +
ggplot2::geom_vline(xintercept = x_vline) +
ggplot2::labs(title = lab.title, subtitle = lab.subtitle) +
ggplot2::theme_minimal() +
ggplot2::theme(legend.title = ggplot2::element_blank())
print(p_scat)
cat("\n\n")
i <- 1
msg <- paste0("## Deployment: ", i, "\n\n")
cat(msg)
# if last one skip
if(i == n_deploy) {
msg <- paste0("Last deployment in file, "
, i
, "/"
, n_deploy
, " .  \n"
, "No comparison able to be made to 'next' deployment."
, "\n\n")
cat(msg)
next
}## IF ~ i == ndeploy
# Start and End Dates
i_A_end <- date_end[i]
i_B_start <- date_start[i + 1]
# 3600 seconds = 1 hour
i_A_start <- i_A_end - (fun.CompHours * 3600)
i_B_end   <- i_B_start + (fun.CompHours * 3600)
# Compare time
i_diff <- as.vector(difftime(i_B_start, i_A_end, units = "hours"))
# Times
msg <- paste0("**A, Start:** ", i_A_start,"\n\n")
cat(msg)
msg <- paste0("**A, End:   ** ", i_A_end,"\n\n")
cat(msg)
msg <- paste0("**B, Start:** ", i_B_start,"\n\n")
cat(msg)
msg <- paste0("**B, End:   ** ", i_B_end,"\n\n")
cat(msg)
msg <- paste0("**Time difference between deployments (hours):** "
, i_diff
, "\n\n")
cat(msg)
msg <- paste0("**Maximum allowable difference (hours):** "
, fun.CompHoursMax
, "\n\n")
cat(msg)
# QC, stop if gap too large
if(i_diff > fun.CompHoursMax) {
msg <- paste0("Maximum time difference exceeded.  "
, "Skipping deployment."
, "\n\n")
cat(msg)
next
}## IF ~ i_diff ~ END
col_Comp <- "Comp"
# Identify the range to examine
df$Comp <- "X"
mark_A <- df$Date.Time > i_A_start & df$Date.Time <= i_A_end
mark_B <- df$Date.Time >= i_B_start & df$Date.Time < i_B_end
df[mark_A, col_Comp] <- "A"
df[mark_B, col_Comp] <- "B"
# Loop through parameters
# get data for comparison
vec_A <- df[df[, col_Comp] == "A", fun.col.Param]
vec_B <- df[df[, col_Comp] == "B", fun.col.Param]
A_last <- vec_A[length(vec_A)]
B_first <- vec_B[1]
diff_spike <- abs(B_first - A_last)
# Comment out t test
# Run function
#rquery.t.test(vec_A, vec_B, paired = TRUE)
# wilcoxon test
#wilcox.test(vec_A, vec_B, paired = TRUE)
col4plot <- c("SiteID", "Date.Time", fun.col.Param, col_Comp)
df_plot <- df[df[, col_Comp] %in% c("A", "B"), col4plot]
# Spike test
msg <- paste0("**A, Last measured value:** "
, A_last
,"\n\n")
cat(msg)
msg <- paste0("**B, First measured value:** "
, B_first
, "\n\n")
cat(msg)
msg <- paste0("**Spike test threshold:** "
, 1.5
, "\n\n")
cat(msg)
msg <- paste0("**Measured value difference:** "
, diff_spike
, "\n\n")
cat(msg)
msg <- "Some statement about spike test, Pass or Fail\n\n"
cat(msg)
# Get parameter
lab.title <- paste0("Deployment end/start comparison; ", i_A_end)
lab.subtitle <- paste0(i, " (A) and ", i+1, " (B)")
# Plot, box
p_box <- ggplot2::ggplot(df_plot, ggplot2::aes_string(x = col_Comp
, y = fun.col.Param
, fill = col_Comp)) +
ggplot2::geom_boxplot() +
ggplot2::labs(title = lab.title
, subtitle = lab.subtitle
, x = "Deployments") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none")
print(p_box)
cat("\n\n")
# Plot, time series
#x_vline <- length(vec_A) + .5 # (i_A_end + i_B_start)/2
x_vline <- i_A_end + i_diff/2 * 3600
# scale_x_date(labels = date_format("%m-%Y"))
# ensure data is date
#df_plot[, "Date.Time"] <- as.Date.POSIXct(df_plot[, "Date.Time"])
p_scat <- ggplot2::ggplot(df_plot, ggplot2::aes_string(x = fun.col.DateTime
, y = fun.col.Param
, color = col_Comp)) +
ggplot2::geom_point() +
ggplot2::geom_vline(xintercept = x_vline) +
ggplot2::labs(title = lab.title, subtitle = lab.subtitle) +
ggplot2::theme_minimal() +
ggplot2::theme(legend.title = ggplot2::element_blank())
print(p_scat)
cat("\n\n")
install.packages(c("broom", "cli", "cpp11", "crayon", "dplyr", "matrixStats", "pixmap", "rappdirs", "rgdal", "systemfonts", "tibble"))
install.packages(c("broom", "cli", "cpp11", "crayon", "dplyr", "matrixStats", "pixmap", "rappdirs", "rgdal", "systemfonts", "tibble"))
install.packages(c("broom", "cli", "cpp11", "crayon", "dplyr", "matrixStats", "pixmap", "rappdirs", "rgdal", "systemfonts", "tibble"))
library(ContDataQC)
?ContDataQC
library(XC95)
?XC95
??XC95
tempdir()
setwd(tempdir)
setwd(tempdir())
# data
data(dta.do)
data(ss.sites)
# function inputs
data.env     <- dta.do
data.sp.wide <- ss.sites
plot         <- T
dogam        <- F
SampleID     <- "Station_Date"
tag          <- "wt"
sortvect     <- NULL
np           <- 61
nt           <- 25
addtrend     <- F
wd           <- getwd()
groups       <- c("BigHUC","ECOREGL3","WS_AREA")
xvar         <- "cond"
groupNames   <- c("HUC04", "EcoL3", "Area")
xvar.PlotName <- "Conductivity (uS/cm)"
# run function (~20 seconds)
df.xc95 <- wt.cdf (data.env, data.sp.wide, plot = T, dogam = T
, SampleID = SampleID, tag = tag, sortvect = NULL
, np = 61, nt = 25, addtrend = T, wd = getwd()
, groups = groups, xvar = xvar, groupNames = groupNames
, xvar.PlotName = xvar.PlotName)
View(df.xc95)
# data
data(dta.do)
data(ss.sites)
# run function (~20 seconds)
dftv.do <- fish.wt.cdf(datafile = dta.do, ss = ss.sites, plot = T, dogam = T
, SampleID = "Station_Date", tag = "wt", sortvect = NULL
, np = 61, nt = 25, addtrend = T
, wd = getwd(), groups = c("BigHUC","ECOREGL3","WS_AREA")
, xvar = "cond")
View(dftv.do)
# Environmental Variables
varlist <- c("lgX3daymax", "lgMAF", "lgFallrate", "lgHigh1fall", "RBI",	"lgX3daymin")
varnames <- c("3-day Max", "Mean Annual Flow", "Fall Rate", "High 1 Fall", "RBI", "3-Day Min")
# select variable
vari <- 1
mydata <- envdata.all[!is.na(envdata.all[,varlist[vari]]),]
# run function
whole.values <- taxon.response(spdata = species, envdata = mydata,  sp.siteid = "BenSampID", species = "OTU",
sp.abndid = "RA", env.siteid = "BenSampID", xvar = varlist[vari], cutoff = 20, region = "tol_all", lim ="GAM",
coord = c("BioSta_Long", "BioSta_Lat"), mtype = 3, dense.N = 201, plot.pdf = T, add.map = F, statename = NULL,
add.lab = F, main = paste("Macroinvertebrates Response to", varnames[vari]), mar = c(5,4,3,2),
xlabs= varnames[vari], log.x = F, rounder = 3, taus = c(0,50,100), nbin = 51, wd = getwd())
# view results
View(whole.values)
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
# Copy Config file to Shiny
# Run each time update master config file (data\config.R)
#
# Erik.Leppo@tetratech.com
# 2021-01-20
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 0. Prep####
wd <- getwd() # assume is package directory
#library(devtools)
# 1. Copy file with new name
config.from <- file.path(".", "R", "config.R")
config.to  <- file.path(".", "inst", "shiny-examples", "ContDataQC"
, "www", "Config.R")
file.copy(config.from, config.to, overwrite = TRUE)
# 2. Copy and save as "TEMPLATE"
config.from <- file.path(".", "R", "config.R")
config.to.template <- file.path(".", "inst", "shiny-examples", "ContDataQC"
, "www", "Config_Template.R")
file.copy(config.from, config.to.template, overwrite = TRUE)
# 3. Copy to extdata
config.from <- file.path(".", "R", "config.R")
config.to   <- file.path(".", "inst", "extdata", "Config.ORIG.R")
file.copy(config.from, config.to, overwrite = TRUE)
# 4. Comment out env.new() in TEMPLATE
###### MANUAL *************************************
# 5. Create zip file from TEMPLATE
###### MANUAL *************************************
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
# Load Library
library(devtools)
## Generate Documentation
devtools::document()
tempdir()
install.packages(c("cachem", "dbplyr", "dplyr", "nlme", "shinyWidgets", "tibble", "wrapr"))
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary
, build_vignettes = TRUE
, quick = FALSE
, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
library(ContDataQC)
?ContDataQC
# Examples of each operation
# 00. Set up
# Parameters
Selection.Operation <- c("GetGageData"
, "QCRaw"
, "Aggregate"
, "SummaryStats")
Selection.Type      <- c("Air","Water","AW","Gage","AWG","AG","WG")
Selection.SUB <- c("Data0_Original"
, "Data1_RAW"
, "Data2_QC"
, "Data3_Aggregated"
, "Data4_Stats")
(myDir.BASE <- tempdir()) # create and print temp directory for example data
# Create data directories
myDir.create <- file.path(myDir.BASE, Selection.SUB[1])
ifelse(dir.exists(myDir.create) == FALSE
, dir.create(myDir.create)
, "Directory already exists")
myDir.create <- file.path(myDir.BASE, Selection.SUB[2])
ifelse(dir.exists(myDir.create) == FALSE
, dir.create(myDir.create)
, "Directory already exists")
myDir.create <- file.path(myDir.BASE, Selection.SUB[3])
ifelse(dir.exists(myDir.create) == FALSE
, dir.create(myDir.create)
, "Directory already exists")
myDir.create <- file.path(myDir.BASE, Selection.SUB[4])
ifelse(dir.exists(myDir.create) == FALSE
, dir.create(myDir.create)
, "Directory already exists")
myDir.create <- file.path(myDir.BASE, Selection.SUB[5])
ifelse(dir.exists(myDir.create) == FALSE
, dir.create(myDir.create)
, "Directory already exists")
# Save example data (assumes myDir.BASE directory exists)
myData <- data_raw_test2_AW_20130426_20130725
write.csv(myData, file.path(myDir.BASE
, Selection.SUB[2]
, "test2_AW_20130426_20130725.csv"))
myData <- data_raw_test2_AW_20130725_20131015
write.csv(myData, file.path(myDir.BASE
, Selection.SUB[2]
, "test2_AW_20130725_20131015.csv"))
myData <- data_raw_test2_AW_20140901_20140930
write.csv(myData, file.path(myDir.BASE
, Selection.SUB[2]
, "test2_AW_20140901_20140930.csv"))
myData <- data_raw_test4_AW_20160418_20160726
write.csv(myData, file.path(myDir.BASE
, Selection.SUB[2]
, "test4_AW_20160418_20160726.csv"))
myFile <- "config.TZ.Central.R"
file.copy(file.path(path.package("ContDataQC"), "extdata", myFile)
, file.path(myDir.BASE, Selection.SUB[2], myFile))
# 02.A. QC Raw Data
myData.Operation       <- "QCRaw" #Selection.Operation[2]
myData.SiteID          <- "test2"
myData.Type            <- Selection.Type[3] #"AW"
myData.DateRange.Start <- "2013-01-01"
myData.DateRange.End   <- "2014-12-31"
myDir.import           <- file.path(myDir.BASE, Selection.SUB[2]) #"Data1_RAW"
myDir.export           <- file.path(myDir.BASE, Selection.SUB[3]) #"Data2_QC"
myReport.format        <- "docx"
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myReport.format = myReport.format)
tempdir()
# 02.B. QC Raw Data (offset collection times for air and water sensors)
myData.Operation       <- "QCRaw" #Selection.Operation[2]
myData.SiteID          <- "test4"
myData.Type            <- Selection.Type[3] #"AW"
myData.DateRange.Start <- "2016-04-28"
myData.DateRange.End   <- "2016-07-26"
myDir.import           <- file.path(myDir.BASE, Selection.SUB[2]) #"Data1_RAW"
myDir.export           <- file.path(myDir.BASE, Selection.SUB[3]) #"Data2_QC"
myReport.format        <- "html"
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myReport.format = myReport.format)
# 03. Aggregate Data
myData.Operation       <- "Aggregate" #Selection.Operation[3]
myData.SiteID          <- "test2"
myData.Type            <- Selection.Type[3] #"AW"
myData.DateRange.Start <- "2013-01-01"
myData.DateRange.End   <- "2014-12-31"
myDir.import           <- file.path(myDir.BASE, Selection.SUB[3]) #"Data2_QC"
myDir.export           <- file.path(myDir.BASE, Selection.SUB[4]) #"Data3_Aggregated"
#Leave off myReport.format and get default (docx).
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export)
# 04. Summary Stats
myData.Operation       <- "SummaryStats" #Selection.Operation[4]
myData.SiteID          <- "test2"
myData.Type            <- Selection.Type[3] #"AW"
myData.DateRange.Start <- "2013-01-01"
myData.DateRange.End   <- "2014-12-31"
myDir.import           <- file.path(myDir.BASE, Selection.SUB[4]) #"Data3_Aggregated"
myDir.export           <- file.path(myDir.BASE, Selection.SUB[5]) #"Data4_Stats"
#Leave off myReport.format and get default (docx).
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export)
# 02.Alt. QC Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
#myFile <- "test2_AW_20130426_20130725.csv"
myFile <- c("test2_AW_20130426_20130725.csv"
, "test2_AW_20130725_20131015.csv"
, "test2_AW_20140901_20140930.csv")
myDir.import <- file.path(myDir.BASE, "Data1_RAW")
myDir.export <- file.path(myDir.BASE, "Data2_QC")
myReport.format <- "docx"
ContDataQC(myData.Operation
, fun.myDir.import = myDir.import
, fun.myDir.export = myDir.export
, fun.myFile = myFile
, fun.myReport.format = myReport.format)
list.files(file.path(myDir.BASE, "Data1_RAW"))
myFile %in% list.files(file.path(myDir.BASE, "Data1_RAW"))
myFile <- c("test2_Aw_20130426_20130725.csv"
, "test2_Aw_20130725_20131015.csv"
, "test2_Aw_20140901_20140930.csv")
myDir.import <- file.path(myDir.BASE, "Data1_RAW")
myDir.export <- file.path(myDir.BASE, "Data2_QC")
myReport.format <- "docx"
ContDataQC(myData.Operation
, fun.myDir.import = myDir.import
, fun.myDir.export = myDir.export
, fun.myFile = myFile
, fun.myReport.format = myReport.format)
list.files(myDir.import)
myFile %in% list.files(myDir.import)
myFile
myFile <- c("test2_AW_20130426_20130725.csv"
, "test2_AW_20130725_20131015.csv"
, "test2_AW_20140901_20140930.csv")
myFile %in% list.files(myDir.import)
