#strFile.plot <- paste(paste(strFile.Prefix.Out,strFile.SiteID,fun.myData.Type,strFile.Date.Start,strFile.Date.End,i,myTimeFrame,sep="_"),"png",sep=".")
#png(file=paste(myDir.data.export,strFile.plot,sep="/"))
plot(stats.i$mean,type=myPlot.Type
,main=i,ylab="mean",xlab=myTimeFrame,xaxt="n"
,ylim=c(min(stats.i$min),max(stats.i$max)))
myCol <- "gray"
graphics::lines(stats.i$max,col=myCol)
graphics::lines(stats.i$min,col=myCol)
graphics::polygon(c(1:nrow(stats.i),rev(1:nrow(stats.i))),c(stats.i$max,rev(stats.i$min)),col=myCol,border=NA)
graphics::lines(stats.i$mean)
# X-Axis
n.Total <- length(factor(stats.i[,"TimeValue"]))
myAT <- 1:n.Total
myLab <- stats.i[,"TimeValue"][myAT]
graphics::axis(1,at=myAT,labels=myLab,tick=TRUE)
#dev.off()
#
#
grDevices::dev.off()##PDF.END
# Combine (all the same so just rbind)
stats.i.ALL <- rbind(stats.i.y, stats.i.s, stats.i.ys, stats.i.m, stats.i.ym, stats.i.jd, stats.i.d)
stats.i.ALL[,ContData.env$myName.SiteID] <- strFile.Base # fun.myData.SiteID
# entire filename since don't/can't know SiteID
# rearrange columns (last 2 to first 2)
myCol.Order <- c(ncol(stats.i.ALL),(ncol(stats.i.ALL)-2),(ncol(stats.i.ALL)-1),1:(ncol(stats.i.ALL)-3))
#stats.i.ALL <- stats.i.ALL[,c(myName.SiteID,(ncol(stats.i.ALL)-2):(ncol(stats.i.ALL)-1),2:ncol(stats.i.ALL)-3)]
stats.i.ALL <- stats.i.ALL[,myCol.Order]
# save stats
strFile.Prefix.Out <- fun.myProcedure.Step
strFile.Out <- paste(paste(strFile.Prefix.Out,strFile.Base,i,sep=ContData.env$myDelim),"csv",sep=".")
#write.csv(stats.i.ALL,paste(myDir.data.export,strFile.Out,sep="/"),quote=FALSE,row.names=FALSE)
utils::write.csv(stats.i.ALL,file.path(myDir.data.export,strFile.Out),quote=FALSE,row.names=FALSE)
#
# need to inform user what part of loop
#
}##FOR.i.END
i
#
i.num <- match(i,myFields.Data)
Fields2Drop <- myFields.Data[-i.num]
data.stats <- data.import[,!(names(data.import) %in% Fields2Drop)]
# change fails to NA (so can na.rm=T when run stats)
# flag field
myFlag <- myFields.Data.Flags[i.num]
# 20170519, feedback to user
print(paste0("Processing item ",i.num," of ",length(data2process),"; ",i))
utils::flush.console()
# change fail to NA for i (only if user define value == FALSE)
if(ContData.env$myStats.Fails.Exclude==TRUE) {##IF.myStats.Fails.Include.START
#
data.stats[,i][data.stats[,myFlag]==ContData.env$myFlagVal.Fail] <- NA
#
}##IF.myStats.Fails.Exclude.END
#
# summaryBy doesn't work with Group as variable (change value for running here)
# have to change some back for dv.i when save
names(data.stats)[names(data.stats) %in% ContData.env$myName.Date] <- "Date"
names(data.stats)[names(data.stats) %in% ContData.env$myName.YrMo] <- "YearMonth"
names(data.stats)[names(data.stats) %in% ContData.env$myName.YrSeason] <- "YearSeason"
names(data.stats)[names(data.stats) %in% ContData.env$myName.Yr] <- "Year"
#                     , var.names="i",id=c(ContData.env$myName.SiteID, "Year", "YearMonth", ContData.env$myName.Mo, ContData.env$myName.MoDa
#                                          , ContData.env$myName.JuDa, ContData.env$myName.Season,"YearSeason"))
# } else if (i==myFields.Data[3]) {
#   dv.i <- doBy::summaryBy(as.numeric(Water.Level.ft)~Date, data=data.stats, FUN=c(mean), na.rm=TRUE
#                     , var.names="i",id=c(ContData.env$myName.SiteID, "Year", "YearMonth", ContData.env$myName.Mo, ContData.env$myName.MoDa
#                                          , ContData.env$myName.JuDa, ContData.env$myName.Season,"YearSeason"))
# }
# 20170519, fix hard coded names
#
# name to myVar then name back
ColNum.i <- match(i,names(data.stats))
names(data.stats)[ColNum.i] <- "myVar"
dv.i <- doBy::summaryBy(as.numeric(myVar)~Date, data=data.stats, FUN=c(mean), na.rm=TRUE
, var.names="i",id=c(ContData.env$myName.SiteID, ContData.env$myName.Yr , ContData.env$myName.YrMo, ContData.env$myName.Mo, ContData.env$myName.MoDa
, ContData.env$myName.JuDa, ContData.env$myName.Season, ContData.env$myName.YrSeason))
?summaryBy
myVar
ColNum.i <- match(i,names(data.stats))
names(data.stats)[ColNum.i] <- "myVar"
names(data.stats)
"myVar" %in% names(data.stats)
doBy::summaryBy(as.numeric(myVar)~Date, data=data.stats, FUN=c(mean), na.rm=TRUE)
summary(data.stats$myVar)
sum(is.na(data.stats$myVar))
doBy::summaryBy(as.numeric(myVar)~Date, data=data.stats, FUN=c(mean), na.rm=TRUE
, var.names="i")
i
ColNum.i
ColNum.i
ColNum.i <- 5
names(data.stats)[ColNum.i]
data(dietox)
dietox12    <- subset(dietox,Time==12)
fun <- function(x){
c(m=mean(x), v=var(x), n=length(x))
}
summaryBy(cbind(Weight, Feed) ~ Evit + Cu, data=dietox12,
FUN=fun)
library(summaryBy)
library(doBy)
data(dietox)
dietox12    <- subset(dietox,Time==12)
fun <- function(x){
c(m=mean(x), v=var(x), n=length(x))
}
summaryBy(cbind(Weight, Feed) ~ Evit + Cu, data=dietox12,
FUN=fun)
head(dietox)
summaryBy(as.numeric(Weight)~Pig, data = dietox, FUN = c(mean), na.rm = TRUE)
summaryBy(Weight~Evit, data = dietox, FUN = c(mean), na.rm = TRUE)
summaryBy(Weight~Evit, data = dietox, FUN = c(mean), na.rm = TRUE, var.names = "i")
summaryBy(as.numeric(Weight)~Evit, data = dietox, FUN = c(mean), na.rm = TRUE, var.names = "i")
?as.numeric
weight
sort(dietox$Weight)
as.numeric(5)
as.numeric("5")
as.numeric(dietox$Weight)
str(dietox)
str(data.stats)
dv.i <- doBy::summaryBy(myVar~Date, data=data.stats, FUN=c(mean), na.rm=TRUE
, var.names="i",id=c(ContData.env$myName.SiteID, ContData.env$myName.Yr , ContData.env$myName.YrMo, ContData.env$myName.Mo, ContData.env$myName.MoDa
, ContData.env$myName.JuDa, ContData.env$myName.Season, ContData.env$myName.YrSeason))
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
library(ContDataQC)
?ContDataQC
# Parameters
Selection.Operation <- c("GetGageData","QCRaw", "Aggregate", "SummaryStats")
Selection.Type      <- c("Air","Water","AW","Gage","AWG","AG","WG")
Selection.SUB <- c("Data0_Original", "Data1_RAW","Data2_QC","Data3_Aggregated","Data4_Stats")
myDir.BASE <- getwd()
# Create data directories
myDir.create <- paste0("./",Selection.SUB[1])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[2])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[3])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[4])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[5])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
# Save example data (assumes directory ./Data1_RAW/ exists)
myData <- data_raw_test2_AW_20130426_20130725
write.csv(myData,paste0("./",Selection.SUB[2],"/test2_AW_20130426_20130725.csv"))
myData <- data_raw_test2_AW_20130725_20131015
write.csv(myData,paste0("./",Selection.SUB[2],"/test2_AW_20130725_20131015.csv"))
myData <- data_raw_test2_AW_20140901_20140930
write.csv(myData,paste0("./",Selection.SUB[2],"/test2_AW_20140901_20140930.csv"))
myData <- data_raw_test4_AW_20160418_20160726
write.csv(myData,paste0("./",Selection.SUB[2],"/test4_AW_20160418_20160726.csv"))
myFile <- "config.TZ.Central.R"
file.copy(file.path(path.package("ContDataQC"),"extdata",myFile)
,file.path(getwd(),Selection.SUB[2],myFile))
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test2"
myData.Type      <- Selection.Type[3] #"AW"
myData.DateRange.Start  <- "2013-01-01"
myData.DateRange.End    <- "2014-12-31"
myDir.import <- file.path(myDir.BASE,Selection.SUB[2]) #"Data1_RAW"
myDir.export <- file.path(myDir.BASE,Selection.SUB[3]) #"Data2_QC"
myReport.format <- "docx"
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export
, fun.myReport.format=myReport.format)
# QC Raw Data (offset collection times for air and water sensors)
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test4"
myData.Type      <- Selection.Type[3] #"AW"
myData.DateRange.Start  <- "2016-04-28"
myData.DateRange.End    <- "2016-07-26"
myDir.import <- file.path(myDir.BASE,Selection.SUB[2]) #"Data1_RAW"
myDir.export <- file.path(myDir.BASE,Selection.SUB[3]) #"Data2_QC"
myReport.format <- "html"
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export
, fun.myReport.format=myReport.format)
# Aggregate Data
myData.Operation <- "Aggregate" #Selection.Operation[3]
myData.SiteID    <- "test2"
myData.Type      <- Selection.Type[3] #"AW"
myData.DateRange.Start  <- "2013-01-01"
myData.DateRange.End    <- "2014-12-31"
myDir.import <- file.path(myDir.BASE,Selection.SUB[3]) #"Data2_QC"
myDir.export <- file.path(myDir.BASE,Selection.SUB[4]) #"Data3_Aggregated"
#Leave off myReport.format and get default (docx).
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export)
# Summary Stats
myData.Operation <- "SummaryStats" #Selection.Operation[4]
myData.SiteID    <- "test2"
myData.Type      <- Selection.Type[3] #"AW"
myData.DateRange.Start  <- "2013-01-01"
myData.DateRange.End    <- "2014-12-31"
myDir.import <- file.path(myDir.BASE,Selection.SUB[4]) #"Data3_Aggregated"
myDir.export <- file.path(myDir.BASE,Selection.SUB[5]) #"Data4_Stats"
#Leave off myReport.format and get default (docx).
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export)
# QC Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
#myFile <- "test2_AW_20130426_20130725.csv"
myFile <- c("test2_AW_20130426_20130725.csv"
, "test2_AW_20130725_20131015.csv"
, "test2_AW_20140901_20140930.csv")
myDir.import <- file.path(".","Data1_RAW")
myDir.export <- file.path(".","Data2_QC")
myReport.format <- "docx"
ContDataQC(myData.Operation, fun.myDir.import=myDir.import
, fun.myDir.export=myDir.export, fun.myFile=myFile
, fun.myReport.format=myReport.format)
# Aggregate Data
myData.Operation <- "Aggregate" #Selection.Operation[3]
myFile <- c("QC_test2_AW_20130426_20130725.csv"
, "QC_test2_AW_20130725_20131015.csv"
, "QC_test2_AW_20140901_20140930.csv")
myDir.import <- file.path(".","Data2_QC")
myDir.export <- file.path(".","Data3_Aggregated")
myReport.format <- "html"
ContDataQC(myData.Operation, fun.myDir.import=myDir.import
, fun.myDir.export=myDir.export, fun.myFile=myFile
, fun.myReport.format=myReport.format)
# Summary Stats
myData.Operation <- "SummaryStats" #Selection.Operation[4]
myFile <- "QC_test2_AW_20130426_20130725.csv"
#myFile <- c("QC_test2_AW_20130426_20130725.csv"
#            , "QC_test2_AW_20130725_20131015.csv"
#            , "QC_test2_AW_20140901_20140930.csv")
myDir.import <- file.path(".","Data2_QC")
myDir.export <- file.path(".","Data4_Stats")
#Leave off myReport.format and get default (docx).
ContDataQC(myData.Operation, fun.myDir.import=myDir.import
, fun.myDir.export=myDir.export, fun.myFile=myFile)
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
library(ContDataQC)
# Parameters
Selection.Operation <- c("GetGageData","QCRaw", "Aggregate", "SummaryStats")
Selection.Type      <- c("Air","Water","AW","Gage","AWG","AG","WG")
Selection.SUB <- c("Data0_Original", "Data1_RAW","Data2_QC","Data3_Aggregated","Data4_Stats")
myDir.BASE <- getwd()
# Create data directories
myDir.create <- paste0("./",Selection.SUB[1])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[2])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[3])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[4])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
myDir.create <- paste0("./",Selection.SUB[5])
ifelse(dir.exists(myDir.create)==FALSE,dir.create(myDir.create),"Directory already exists")
# QC Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
#myFile <- "test2_AW_20130426_20130725.csv"
myFile <- c("test2_AW_20130426_20130725.csv"
, "test2_AW_20130725_20131015.csv"
, "test2_AW_20140901_20140930.csv")
myDir.import <- file.path(".","Data1_RAW")
myDir.export <- file.path(".","Data2_QC")
myReport.format <- "docx"
ContDataQC(myData.Operation, fun.myDir.import=myDir.import
, fun.myDir.export=myDir.export, fun.myFile=myFile
, fun.myReport.format=myReport.format)
# Aggregate Data
myData.Operation <- "Aggregate" #Selection.Operation[3]
myFile <- c("QC_test2_AW_20130426_20130725.csv"
, "QC_test2_AW_20130725_20131015.csv"
, "QC_test2_AW_20140901_20140930.csv")
myDir.import <- file.path(".","Data2_QC")
myDir.export <- file.path(".","Data3_Aggregated")
myReport.format <- "html"
ContDataQC(myData.Operation, fun.myDir.import=myDir.import
, fun.myDir.export=myDir.export, fun.myFile=myFile
, fun.myReport.format=myReport.format)
# Summary Stats
myData.Operation <- "SummaryStats" #Selection.Operation[4]
myFile <- "QC_test2_AW_20130426_20130725.csv"
#myFile <- c("QC_test2_AW_20130426_20130725.csv"
#            , "QC_test2_AW_20130725_20131015.csv"
#            , "QC_test2_AW_20140901_20140930.csv")
myDir.import <- file.path(".","Data2_QC")
myDir.export <- file.path(".","Data4_Stats")
#Leave off myReport.format and get default (docx).
ContDataQC(myData.Operation, fun.myDir.import=myDir.import
, fun.myDir.export=myDir.export, fun.myFile=myFile)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Save example data (assumes directory exists)
myFile <- c("QC_Ellis~1.0m_Water_20180524_20180918.csv"
, "QC_Ellis~3.0m_Water_20180524_20180918.csv")
file.copy(file.path(system.file("extdata", package="ContDataQC"), myFile)
, file.path(getwd(), Selection.SUB[3], myFile))
# Aggregate Data
myData.Operation <- "Aggregate" #Selection.Operation[3]
#myFile <- c("QC_Ellis~1.0m_Water_20180524_20180918.csv"
, "QC_Ellis~3.0m_Water_20180524_20180918.csv")
myDir.import <- file.path(".","Data2_QC")
myDir.export <- file.path(".","Data3_Aggregated")
myReport.format <- "html"
ContDataQC(myData.Operation, fun.myDir.import=myDir.import
, fun.myDir.export=myDir.export, fun.myFile=myFile
, fun.myReport.format=myReport.format)
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test2"
myData.Type      <- Selection.Type[3] #"AW"
myData.DateRange.Start  <- "2013-01-01"
myData.DateRange.End    <- "2014-12-31"
myDir.import <- file.path(myDir.BASE,Selection.SUB[2]) #"Data1_RAW"
myDir.export <- file.path(myDir.BASE,Selection.SUB[3]) #"Data2_QC"
myReport.format <- "docx"
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export
, fun.myReport.format=myReport.format)
# QC Raw Data (offset collection times for air and water sensors)
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test4"
myData.Type      <- Selection.Type[3] #"AW"
myData.DateRange.Start  <- "2016-04-28"
myData.DateRange.End    <- "2016-07-26"
myDir.import <- file.path(myDir.BASE,Selection.SUB[2]) #"Data1_RAW"
myDir.export <- file.path(myDir.BASE,Selection.SUB[3]) #"Data2_QC"
myReport.format <- "html"
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export
, fun.myReport.format=myReport.format)
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test2"
myData.Type      <- Selection.Type[3] #"AW"
myData.DateRange.Start  <- "2013-01-01"
myData.DateRange.End    <- "2014-12-31"
myDir.import <- file.path(myDir.BASE,Selection.SUB[2]) #"Data1_RAW"
myDir.export <- file.path(myDir.BASE,Selection.SUB[3]) #"Data2_QC"
myReport.format <- "docx"
list.files(myDir.import)
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export
, fun.myReport.format=myReport.format)
ContDataQC(myData.Operation, myData.SiteID, myData.Type, myData.DateRange.Start
, myData.DateRange.End, myDir.import, myDir.export
, fun.myReport.format=myReport.format)
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
shiny::runApp('inst/shiny-examples/ContDataQC')
runApp('inst/shiny-examples/ContDataQC')
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
devtools::install_github("leppott/ContDataQC", force = TRUE)
getwd()
list.files(getwd())
list.files("data")
list.files(file.path(".", "data"))
list.files(file.path("data"))
shiny::runApp('inst/shiny-examples/ContDataQC')
x <- "12_23_45"
gsub("_", "", x)
Sys.time()
time <- Sys.time()
time
time2 <- gsub(":", "_", time)
time3 <- gsub("-", "", time2)
time4 <- gsub(" ", "_", time3)
return(time4)
time4
sub("_","", time4)
gsub("_","", time4)
?substr
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
shiny::runApp('inst/shiny-examples/ContDataQC')
devtools::install_github("leppott/ContDataQC", force = true)
devtools::install_github("leppott/ContDataQC", force = TRUE)
dir <- ""
myDir <- "C:\Users\Erik.Leppo\OneDrive - Tetra Tech, Inc\MyDocs_OneDrive\_HOME\RMN\Issue_KY\Reformat"
myDir <- "C:\\Users\\Erik.Leppo\\OneDrive - Tetra Tech, Inc\\MyDocs_OneDrive\\_HOME\\RMN\\Issue_KY\\Reformat"
list.files(myDir)
names(data.import)
library(ContDataQC)
?ContDataQC
