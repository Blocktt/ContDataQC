# create log file for processing results of items
#myItems.Log <- data.frame(cbind(myItems.ALL,NA),stringsAsFactors=FALSE)
myItems.Log <- data.frame(ItemID=1:intItems.Total,Status=NA,ItemName=myItems.ALL)
intCounter
intCounter <- 4
#
# B.0. Increase the Counter
intCounter <- intCounter+1
#
# B.1.0. File Name, Define
strFile = files2process[intCounter]
# 1.1. File Name, Parse
# QC Check - delimiter for strsplit
if(ContData.env$myDelim==".") {##IF.myDelim.START
# special case for regex check to follow (20170531)
myDelim.strsplit <- "\\."
} else {
myDelim.strsplit <- ContData.env$myDelim
}##IF.myDelim.END
strFile.Base <- substr(strFile,1,nchar(strFile)-nchar(".csv"))
strFile.parts <- strsplit(strFile.Base, myDelim.strsplit)
strFile.SiteID     <- strFile.parts[[1]][1]
strFile.DataType   <- strFile.parts[[1]][2]
# Convert Data Type to proper case
strFile.DataType <- paste(toupper(substring(strFile.DataType,1,1)),tolower(substring(strFile.DataType,2,nchar(strFile.DataType))),sep="")
strFile.Date.Start <- as.Date(strFile.parts[[1]][3],"%Y%m%d")
strFile.Date.End   <- as.Date(strFile.parts[[1]][4],"%Y%m%d")
#
# B.2. Check File and skip if doesn't match user defined parameters
# B.2.1. Check File Size
#if(file.info(paste(myDir.data.import,"/",strFile,sep=""))$size==0){
if(file.info(file.path(myDir.data.import,strFile))$size==0){
# inform user of progress and update LOG
myMsg <- "SKIPPED (file blank)"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
next
}
# B.2.2. Check SiteID
# if not in provided site list then skip
if(strFile.SiteID %in% fun.myData.SiteID == FALSE) {
# inform user of progress and update LOG
myMsg <- "SKIPPED (Non-Match, SiteID)"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
next
}
# B.2.3. Check DataType
# if not equal go to next file (handles both Air and Water)
if (strFile.DataType %in% fun.myData.Type == FALSE){
# inform user of progress and update LOG
myMsg <- "SKIPPED (Non-Match, DataType)"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
next
}
# B.2.4. Check Dates
# B.2.4.2.1. Check File.Date.Start (if file end < my Start then next)
if(strFile.Date.End<fun.myData.DateRange.Start) {
# inform user of progress and update LOG
myMsg <- "SKIPPED (Non-Match, Start Date)"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
next
}
# B.2.4.2.2. Check File.Date.End (if file Start > my End then next)
if(strFile.Date.Start>fun.myData.DateRange.End) {
# inform user of progress and update LOG
myMsg <- "SKIPPED (Non-Match, End Date)"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
next
}
#
# B.3.0. Import the data
#data.import=read.table(strFile,header=F,varSep)
#varSep = "\t" (use read.delim instead of read.table)
# as.is = T so dates come in as text rather than factor
#data.import <- read.delim(strFile,as.is=TRUE,na.strings="")
# data.import <- read.csv(paste(myDir.data.import,strFile,sep="/"),as.is=TRUE,na.strings=c("","NA"))
data.import <- read.csv(file.path(myDir.data.import,strFile),as.is=TRUE,na.strings=c("","NA"))
#
# QC required fields: SiteID & (DateTime | (Date & Time))
fun.QC.ReqFlds(names(data.import),paste(myDir.data.import,strFile,sep="/"))
names(data.import)
#
# B.4.0. Columns
# Kick out if missing minimum of fields
#
# Check for and add any missing columns (but not for missing data fields)
# B.4.1. Date, Time, DateTime
# list
strCol.DT <- c(ContData.env$myName.Date,ContData.env$myName.Time,ContData.env$myName.DateTime)
# check for missing
strCol.DT.Missing <- strCol.DT[strCol.DT %in% colnames(data.import)==FALSE]
strCol.DT.Missing
# go to next item if no date, time, or date/time field
if(length(strCol.DT.Missing)==3) {
myMsg <- "SKIPPED (Missing Fields, Date/Time)"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
next
}
# go to next item if no (date or time) AND no date/time field  (i.e., only 1 of date or time)
if(length(strCol.DT.Missing)==2 & ContData.env$myName.DateTime%in%strCol.DT.Missing==TRUE) {
myMsg <- "SKIPPED (Missing Fields, 'Date.Time' and one of 'Date' or 'Time')"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
next
}
#
# add to df
data.import[,strCol.DT.Missing] <- NA
#
# B.4.2.  Check for columns present and reorder columns
# check for columns present
strCol.Present <- ContData.env$myNames.Order[ContData.env$myNames.Order %in% colnames(data.import)==TRUE]
#
myNames.DataFields.Present <- ContData.env$myNames.DataFields[ContData.env$myNames.DataFields %in% colnames(data.import)==TRUE]
# kick out if no data fields
if(length(myNames.DataFields.Present)==0){
myMsg <- "SKIPPED (Missing Fields, DATA)"
myItems.Skipped <- myItems.Skipped + 1
myItems.Log[intCounter,2] <- myMsg
fun.write.log(myItems.Log,myDate,myTime)
fun.Msg.Status(myMsg, intCounter, intItems.Total, strFile)
flush.console()
# go to next Item
}
#
# reorder Columns (and drop extra columns)
data.import <- data.import[,strCol.Present]
# B.4.3. Add FLAGS
strCol.Flags <- ContData.env$myNames.Flags[ContData.env$myNames.Cols4Flags %in% colnames(data.import)==TRUE]
data.import[,strCol.Flags] <- ""
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# get format - if all data NA then get an error
#
# backfill first?
#
# may have to add date and time (data) from above when add the missing field.
#if does not exists then add field and data.
#
# if entire field is NA then fill from other fields
# Date
myField   <- ContData.env$myName.Date
data.import[,myField][all(is.na(data.import[,myField]))] <- data.import[,ContData.env$myName.DateTime]
# Time
myField   <- ContData.env$myName.Time
data.import[,myField][all(is.na(data.import[,myField]))] <- data.import[,ContData.env$myName.DateTime]
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Library Name
myLibrary <- "ContDataQC"
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub/"
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
setwd(file.path(dir_base, myLibrary))
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
pkg <- "ContDataQC"
library(pkg, character.only = TRUE)
myDir <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/_HOME/RedLakes/TimEmail_20200825"
setwd(myDir)
dir_pkg <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub/ContDataQC/R"
library(ContDataQC)
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test4Tim"
myData.Type      <- "AW"
myData.DateRange.Start  <- "2016-01-01"
myData.DateRange.End    <- "2016-12-31"
myDir.import <- file.path(".", "Data1_RAW")
myDir.export <- file.path(".", "Data2_QC")
myReport.format <- "html"
myConfig <- "Config_Tim_Full.R"
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myConfig = myConfig
, fun.myReport.format=myReport.format)
setwd("C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub/ContDataQC")
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
pkg <- "ContDataQC"
library(pkg, character.only = TRUE)
# Directory
myDir <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/_HOME/RedLakes/TimEmail_20200825"
setwd(myDir)
#
dir_pkg <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub/ContDataQC/R"
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test4Tim"
myData.Type      <- "AW"
myData.DateRange.Start  <- "2016-01-01"
myData.DateRange.End    <- "2016-12-31"
myDir.import <- file.path(".", "Data1_RAW")
myDir.export <- file.path(".", "Data2_QC")
myReport.format <- "html"
myConfig <- "Config_Tim_Full.R"
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myConfig = myConfig
, fun.myReport.format=myReport.format)
myDelim2Check
names(data.import)
ContData.env$myName.Date
ContData.env$myName.DateTime
View(ContData.env)
View(ContData.env)
ContData.env$myName.DateTime
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
# Directory
myDir <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/_HOME/RedLakes/TimEmail_20200825"
setwd(myDir)
#
dir_pkg <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub/ContDataQC/R"
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test4Tim"
myData.Type      <- "AW"
myData.DateRange.Start  <- "2016-01-01"
myData.DateRange.End    <- "2016-12-31"
myDir.import <- file.path(".", "Data1_RAW")
myDir.export <- file.path(".", "Data2_QC")
myReport.format <- "html"
myConfig <- "Config_Tim_Full.R"
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myConfig = myConfig
, fun.myReport.format=myReport.format)
library(ContDataQC)
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myConfig = myConfig
, fun.myReport.format=myReport.format)
ContData.env$myName.WaterTemp
fun.myConfig
config.load(fun.myConfig)
fun.myConfig
getwd()
list.files()
fun.myConfig %in% list.files()
config.load(fun.myConfig)
View(ContData.env)
config.load(fun.myConfig)
ContData.env$myName.WaterTemp
myFile
myFile <- fun.myConfig
exists("ContData.env", mode = "environment")
myExt="R"
if(exists("ContData.env", mode = "environment") == TRUE){
# intialize new env
ContData.env.original <- new.env(parent = emptyenv())
# copy current env to backup env
ContData.env.original <- ContData.env
}## exists ~ END
myEXT <- toupper(myExt)
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myConfig = myConfig
, fun.myReport.format=myReport.format)
ContData.env$myName.WaterTemp
source(fun.myConfig, local = TRUE)
ContData.env$myName.WaterTemp
library(ContDataQC)
# Directory
myDir <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/_HOME/RedLakes/TimEmail_20200825"
setwd(myDir)
#
dir_pkg <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub/ContDataQC/R"
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test4Tim"
myData.Type      <- "AW"
myData.DateRange.Start  <- "2016-01-01"
myData.DateRange.End    <- "2016-12-31"
myDir.import <- file.path(".", "Data1_RAW")
myDir.export <- file.path(".", "Data2_QC")
myReport.format <- "html"
myConfig <- "Config_Tim_Full.R"
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myConfig = myConfig
, fun.myReport.format=myReport.format)
ContData.env$myName.WaterTemp
View(ContData.env)
# Directory
myDir <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/_HOME/RedLakes/TimEmail_20200825"
setwd(myDir)
#
dir_pkg <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub/ContDataQC/R"
# QC Raw Data
myData.Operation <- "QCRaw" #Selection.Operation[2]
myData.SiteID    <- "test4Tim"
myData.Type      <- "AW"
myData.DateRange.Start  <- "2016-01-01"
myData.DateRange.End    <- "2016-12-31"
myDir.import <- file.path(".", "Data1_RAW")
myDir.export <- file.path(".", "Data2_QC")
myReport.format <- "html"
myConfig <- "Config_Tim_Full.R"
library(ContDataQC)
ContDataQC(myData.Operation
, myData.SiteID
, myData.Type
, myData.DateRange.Start
, myData.DateRange.End
, myDir.import
, myDir.export
, fun.myConfig = myConfig
, fun.myReport.format=myReport.format)
View(ContData.env)
exists("ContData.env", mode = "environment")
search()
ls(ContData.env)
ls.str(ContData.env)
View(ContData.env)
ContData.env$myReport.Format
ContData.env$myName.WaterTemp
ContData.env$myName.WaterTemp
ContData.env$myName.WaterTemp
intCounter < 4
intCounter <- 4
head(data.import)
names(data.import)
ContData.env$myName.SiteID
ContData.env$myName.DateTime
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
# Set working directory
myLibrary <- "ContDataQC"
dir_base <- "C:/Users/Erik.Leppo/OneDrive - Tetra Tech, Inc/MyDocs_OneDrive/GitHub"
setwd(file.path(dir_base, myLibrary))
#
# NEWS
# Render then Copy NEWS so picked up in help
rmarkdown::render("NEWS.rmd", "all")
file.copy("NEWS.md", "NEWS", overwrite = TRUE)
file.remove("NEWS.html")
file.remove("NEWS.md")
#
# Load Library
library(devtools)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Create Package
# create(myLibrary)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Document, Install, and Reload Library
## Generate Documentation
devtools::document()
## Install New Package (locally)
setwd("..") # return to root directory first
devtools::install(myLibrary, build_vignettes = TRUE, quick = FALSE, reload = TRUE)
## Reload library
library(myLibrary,character.only = TRUE)
# change wd back to package
setwd(file.path(dir_base, myLibrary))
